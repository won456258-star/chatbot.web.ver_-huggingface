# íŒŒì¼ëª…: rag_logic.py

import streamlit as st
# â— [ìˆ˜ì •] ìµœì‹  ì„ë² ë”© í´ë˜ìŠ¤ë¥¼ import í•©ë‹ˆë‹¤.
from langchain_huggingface import HuggingFaceEmbeddings, HuggingFaceEndpoint
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
# â— [ìˆ˜ì •] RunnablePassthroughë¥¼ import í•©ë‹ˆë‹¤.
from langchain_core.runnables import RunnablePassthrough

# web.pyì—ì„œ ì—ëŸ¬ë¥¼ ì¡ì•„ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì‚¬ìš©ì ì •ì˜ ì—ëŸ¬ë¥¼ ë§Œë“­ë‹ˆë‹¤.
class RagChainInitializationError(Exception):
    pass

@st.cache_resource
def get_rag_chain(api_key: str):
    """
    Hugging Face API í‚¤ë¥¼ ì¸ìë¡œ ë°›ì•„ RAG ì²´ì¸ì„ ìƒì„±í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤.
    ì˜¤ë¥˜ ë°œìƒ ì‹œ RagChainInitializationErrorë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤.
    """
    try:
        # 1. ì„ë² ë”© ëª¨ë¸ ì„¤ì • (ìµœì‹  í´ë˜ìŠ¤ë¡œ ë³€ê²½)
        # â— [ìˆ˜ì •] SentenceTransformerEmbeddings -> HuggingFaceEmbeddings
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )

        # 2. FAISS ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ
        vectorstore = FAISS.load_local(
            "my_faiss_db",
            embeddings,
            allow_dangerous_deserialization=True
        )
        retriever = vectorstore.as_retriever()

        # 3. LLM ì´ˆê¸°í™” (ì „ë‹¬ë°›ì€ API í‚¤ ì‚¬ìš©)
        HUGGING_FACE_MODEL_ID = "google/gemma-2b-it"

        llm = HuggingFaceEndpoint(
            repo_id=HUGGING_FACE_MODEL_ID,
            huggingfacehub_api_token=api_key,
            task="text-generation",
            max_new_tokens=512,
            temperature=0.1,
        )

        # 4. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
        template = """ë‹¹ì‹ ì€ 'ëª¨êµ¬' ì„œë¹„ìŠ¤ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
        ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”.
        ì‘ë‹µì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ í•´ ì£¼ì„¸ìš”.

        ì»¨í…ìŠ¤íŠ¸:
        {context}

        ì§ˆë¬¸:
        {question}

        ë‹µë³€:
        """
        prompt = ChatPromptTemplate.from_template(template)

        # 5. RAG ì²´ì¸ êµ¬ì„± (RunnablePassthrough ì‚¬ìš©)
        # â— [ìˆ˜ì •] itemgetter ëŒ€ì‹  RunnablePassthroughë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ëª…í™•í•˜ê²Œ êµ¬ì„±í•©ë‹ˆë‹¤.
        rag_chain = (
            {
                "context": retriever,
                "question": RunnablePassthrough(),
            }
            | prompt
            | llm
            | StrOutputParser()
        )

        return rag_chain

    except Exception as e:
        # ğŸš« st.error()ë¥¼ í˜¸ì¶œí•˜ëŠ” ëŒ€ì‹ , ì˜ˆì™¸ë¥¼ ë°œìƒì‹œì¼œ web.pyì— ì•Œë¦½ë‹ˆë‹¤.
        raise RagChainInitializationError(f"RAG ì²´ì¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")